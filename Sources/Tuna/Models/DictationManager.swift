import Foundation
import AVFoundation
import SwiftUI
import Combine
import os.log
// import Views -- å·²ç§»è‡³ Tuna æ¨¡å—

// æ·»åŠ é”™è¯¯æšä¸¾
public enum DictationError: Error, LocalizedError {
    case noAPIKey
    case audioFileReadError
    case transcriptionFailed(Error)
    
    public var errorDescription: String? {
        switch self {
        case .noAPIKey:
            return "No API key provided. Please add your OpenAI API key in Settings."
        case .audioFileReadError:
            return "Could not read audio file."
        case .transcriptionFailed(let error):
            return "Transcription failed: \(error.localizedDescription)"
        }
    }
}

// æ·»åŠ é€šçŸ¥åç§°æ‰©å±•
extension Notification.Name {
    static let dictationAPIKeyMissing = Notification.Name("dictationAPIKeyMissing")
    static let dictationAPIKeyUpdated = Notification.Name("dictationAPIKeyUpdated")
}

public class DictationManager: ObservableObject, DictationManagerProtocol {
    public static let shared = DictationManager()
    
    private let logger = Logger(subsystem: "com.tuna.app", category: "DictationManager")
    private let tunaSettings = TunaSettings.shared
    
    // æ·»åŠ å¯åŠ¨å¤±è´¥å›è°ƒ
    public var onStartFailure: (() -> Void)?
    
    // çŠ¶æ€å’Œæ¶ˆæ¯
    @Published public var state: DictationState = .idle {
        didSet {
            if oldValue != state {
                // å‘é€çŠ¶æ€å˜æ›´é€šçŸ¥
                DispatchQueue.main.async {
                    NotificationCenter.default.post(
                        name: NSNotification.Name("dictationStateChanged"),
                        object: nil,
                        userInfo: ["state": self.state]
                    )
                }
                
                // æ ¹æ®çŠ¶æ€è‡ªåŠ¨æ›´æ–°UIçŠ¶æ€å˜é‡
                switch state {
                case .recording:
                    isRecording = true
                    isPaused = false
                case .paused:
                    isRecording = true
                    isPaused = true 
                case .idle, .error, .processing:
                    isRecording = false
                    isPaused = false
                }
                
                // è®°å½•çŠ¶æ€å˜æ›´
                logger.debug("Dictation state changed from \(String(describing: oldValue)) to \(String(describing: self.state))")
            }
        }
    }
    @Published public var progressMessage: String = ""
    @Published public var transcribedText: String = ""
    
    // UIç›¸å…³çš„çŠ¶æ€
    @Published public var isRecording: Bool = false
    @Published public var isPaused: Bool = false
    @Published public var breathingAnimation: Bool = false
    
    // å½•éŸ³ç›¸å…³
    private var audioRecorder: AVAudioRecorder?
    private var recordingURL: URL?
    private var tempDirectory: URL?
    private var recordingParts: [URL] = []
    // è·Ÿè¸ªå·²è½¬å½•çš„ç‰‡æ®µ
    private var processedSegments: Set<URL> = []
    
    // ä¿®æ”¹APIå¯†é’¥è·å–æ–¹å¼ï¼Œä½¿ç”¨SecureStore
    private var apiKey: String {
        SecureStore.currentAPIKey() ?? ""
    }
    
    private init() {
        logger.debug("DictationManager initialized")
        
        // åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå¤„ç†éŸ³é¢‘æ–‡ä»¶
        tempDirectory = FileManager.default.temporaryDirectory.appendingPathComponent("tuna_dictation", isDirectory: true)
        
        do {
            try FileManager.default.createDirectory(at: tempDirectory!, withIntermediateDirectories: true)
        } catch {
            logger.error("Failed to create temp directory: \(error.localizedDescription)")
        }
        
        setupRecordingSession()
    }
    
    // MARK: - Public Methods
    
    // æ·»åŠ toggleæ–¹æ³•ï¼Œæ ¹æ®å½“å‰çŠ¶æ€åˆ‡æ¢å½•éŸ³çŠ¶æ€
    public func toggle() {
        switch state {
        case .idle:
            startRecording()
        case .recording:
            stopRecording()
        case .paused:
            resumeRecording()
        case .processing, .error:
            // è¿™äº›çŠ¶æ€ä¸‹ä¸åšä»»ä½•æ“ä½œ
            logger.warning("Toggle called while in processing or error state - ignored")
            break
        }
    }
    
    public func resumeRecording() {
        if state == .paused {
            continueRecording()
        }
    }
    
    public func startRecording() {
        logger.notice("å¼€å§‹å½•éŸ³...")
        
        // å¦‚æœå·²ç»åœ¨å½•éŸ³ï¼Œç›´æ¥è¿”å›
        if isRecording {
            logger.notice("å·²ç»åœ¨å½•éŸ³ä¸­ï¼Œå¿½ç•¥è¯·æ±‚")
            return
        }
        
        progressMessage = "å‡†å¤‡å½•éŸ³..."
        
#if os(iOS)
        // æ£€æŸ¥éº¦å…‹é£æƒé™ - iOSç‰ˆæœ¬
        let audioSession = AVAudioSession.sharedInstance()
        switch audioSession.recordPermission {
        case .denied:
            logger.error("éº¦å…‹é£æƒé™è¢«æ‹’ç»")
            progressMessage = "éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£"
            onStartFailure?()
            return
            
        case .undetermined:
            logger.notice("éº¦å…‹é£æƒé™æœªç¡®å®šï¼Œè¯·æ±‚æƒé™")
            audioSession.requestRecordPermission { [weak self] allowed in
                guard let self = self else { return }
                if !allowed {
                    logger.error("ç”¨æˆ·æ‹’ç»äº†éº¦å…‹é£æƒé™")
                    self.progressMessage = "éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£"
                    self.onStartFailure?()
                    return
                }
                // æƒé™è·å–æˆåŠŸï¼Œç»§ç»­å½•éŸ³æµç¨‹
                DispatchQueue.main.async {
                    self.continueRecording()
                }
            }
            return
            
        case .granted:
            logger.notice("éº¦å…‹é£æƒé™å·²è·å–")
            // ç»§ç»­å½•éŸ³æµç¨‹
        @unknown default:
            logger.error("æœªçŸ¥çš„éº¦å…‹é£æƒé™çŠ¶æ€")
            progressMessage = "æœªçŸ¥çš„éº¦å…‹é£æƒé™çŠ¶æ€"
            onStartFailure?()
            return
        }
#else
        // macOSç‰ˆæœ¬ - ä½¿ç”¨AVCaptureDeviceæ£€æŸ¥æƒé™
        if #available(macOS 10.14, *) {
            switch AVCaptureDevice.authorizationStatus(for: .audio) {
            case .denied, .restricted:
                logger.error("éº¦å…‹é£æƒé™è¢«æ‹’ç»æˆ–å—é™")
                progressMessage = "éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨ç³»ç»Ÿåå¥½è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£"
                onStartFailure?()
                return
                
            case .notDetermined:
                logger.notice("éº¦å…‹é£æƒé™æœªç¡®å®šï¼Œè¯·æ±‚æƒé™")
                AVCaptureDevice.requestAccess(for: .audio) { [weak self] allowed in
                    guard let self = self else { return }
                    if !allowed {
                        logger.error("ç”¨æˆ·æ‹’ç»äº†éº¦å…‹é£æƒé™")
                        self.progressMessage = "éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨ç³»ç»Ÿåå¥½è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£"
                        self.onStartFailure?()
                        return
                    }
                    // æƒé™è·å–æˆåŠŸï¼Œç»§ç»­å½•éŸ³æµç¨‹
                    DispatchQueue.main.async {
                        self.continueRecording()
                    }
                }
                return
                
            case .authorized:
                logger.notice("éº¦å…‹é£æƒé™å·²è·å–")
                // ç»§ç»­å½•éŸ³æµç¨‹
            @unknown default:
                logger.error("æœªçŸ¥çš„éº¦å…‹é£æƒé™çŠ¶æ€")
                progressMessage = "æœªçŸ¥çš„éº¦å…‹é£æƒé™çŠ¶æ€"
                onStartFailure?()
                return
            }
        } else {
            // æ—§ç‰ˆmacOSé»˜è®¤æœ‰æƒé™ï¼Œä½†è®°å½•æ—¥å¿—
            logger.notice("macOS 10.14ä»¥ä¸‹ç‰ˆæœ¬æ— æ³•æ£€æŸ¥éº¦å…‹é£æƒé™ï¼Œé»˜è®¤ç»§ç»­")
        }
#endif

        continueRecording()
    }
    
    private func continueRecording() {
        Logger(subsystem:"ai.tuna",category:"Shortcut").notice("[R] startRecording() actually called")
        
        // ç¡®ä¿æˆ‘ä»¬å¤„äºæ­£ç¡®çš„çŠ¶æ€
        guard state == .idle || state == .paused else {
            logger.warning("Cannot start recording - wrong state")
            return
        }
        
        // å¦‚æœå¤„äºæš‚åœçŠ¶æ€ï¼Œåˆ›å»ºæ–°çš„å½•éŸ³ç‰‡æ®µ
        if state == .paused && audioRecorder != nil {
            // ä¿å­˜å·²æœ‰çš„audioRecorderç”¨äºæ¸…ç†
            let oldRecorder = audioRecorder
            
            // åˆ›å»ºæ–°çš„å½•éŸ³æ–‡ä»¶
            let fileName = "dictation_\(Date().timeIntervalSince1970).wav"
            recordingURL = tempDirectory?.appendingPathComponent(fileName)
            
            guard let recordingURL = recordingURL else {
                logger.error("Failed to create recording URL")
                progressMessage = "âš ï¸ æ— æ³•åˆ›å»ºå½•éŸ³æ–‡ä»¶"
                onStartFailure?()
                return
            }
            
            // è®¾ç½®å½•éŸ³å‚æ•° - ä½¿ç”¨æ›´ç®€å•çš„WAVæ ¼å¼ï¼Œæ›´å®¹æ˜“è¢«Whisper APIå¤„ç†
            let settings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatLinearPCM), // ä½¿ç”¨æ— æŸPCMæ ¼å¼
                AVSampleRateKey: 16000.0, // 16kHzé‡‡æ ·ç‡ï¼ŒWhisperæ¨¡å‹æ¥å—è¿™ä¸ªé‡‡æ ·ç‡
                AVNumberOfChannelsKey: 1, // å•å£°é“
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue,
                AVLinearPCMBitDepthKey: 16, // 16ä½
                AVLinearPCMIsBigEndianKey: false,
                AVLinearPCMIsFloatKey: false
            ]
            
            do {
                audioRecorder = try AVAudioRecorder(url: recordingURL, settings: settings)
                audioRecorder?.delegate = nil
                audioRecorder?.record()
                
                // æ·»åŠ åˆ°å½•éŸ³éƒ¨åˆ†åˆ—è¡¨
                recordingParts.append(recordingURL)
                
                // åœæ­¢å¹¶é‡Šæ”¾æ—§çš„å½•éŸ³å™¨
                oldRecorder?.stop()
                
                // æ›´æ–°çŠ¶æ€
                DispatchQueue.main.async {
                    self.state = .recording
                    self.progressMessage = "ğŸ™ æ­£åœ¨å½•éŸ³..."
                    
                    // è§¦å‘UIæ›´æ–°
                    let current = self.transcribedText
                    self.transcribedText = ""
                    self.transcribedText = current
                }
                
                logger.debug("Created new recording segment at \(recordingURL.path)")
                logger.notice("state -> recording (continue)")
            } catch {
                logger.error("Failed to continue recording: \(error.localizedDescription)")
                progressMessage = "âš ï¸ å½•éŸ³å¤±è´¥: \(error.localizedDescription)"
                
                // æ¢å¤æ—§çš„å½•éŸ³å™¨çŠ¶æ€
                audioRecorder = oldRecorder
                onStartFailure?()
            }
            
            return
        }
        
        // å¦‚æœä¸æ˜¯ä»æš‚åœçŠ¶æ€ç»§ç»­ï¼Œåˆ™æ¸…é™¤å·²æœ‰çš„è½¬å½•å†…å®¹å¹¶å¼€å§‹æ–°å½•éŸ³
        if state == .idle {
            // æ¸…é™¤è½¬å½•æ–‡æœ¬ä»¥å¼€å§‹æ–°å½•éŸ³
            transcribedText = ""
            recordingParts = []
            processedSegments = [] // é‡ç½®å·²å¤„ç†ç‰‡æ®µè®°å½•
        }
        
        // åˆ›å»ºæ–°çš„å½•éŸ³æ–‡ä»¶
        let fileName = "dictation_\(Date().timeIntervalSince1970).wav"
        recordingURL = tempDirectory?.appendingPathComponent(fileName)
        
        guard let recordingURL = recordingURL else {
            logger.error("Failed to create recording URL")
            progressMessage = "âš ï¸ æ— æ³•åˆ›å»ºå½•éŸ³æ–‡ä»¶"
            onStartFailure?()
            return
        }
        
        // è®¾ç½®å½•éŸ³å‚æ•°
        let settings: [String: Any] = [
            AVFormatIDKey: Int(kAudioFormatLinearPCM),
            AVSampleRateKey: 16000.0,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue,
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsBigEndianKey: false,
            AVLinearPCMIsFloatKey: false
        ]
        
        do {
            audioRecorder = try AVAudioRecorder(url: recordingURL, settings: settings)
            audioRecorder?.delegate = nil
            audioRecorder?.record()
            
            // æ·»åŠ åˆ°å½•éŸ³éƒ¨åˆ†åˆ—è¡¨
            recordingParts.append(recordingURL)
            
            state = .recording
            progressMessage = "ğŸ™ æ­£åœ¨å½•éŸ³..."
            logger.debug("Started new recording at \(recordingURL.path)")
            logger.notice("state -> recording (new)")
        } catch {
            logger.error("Failed to start recording: \(error.localizedDescription)")
            progressMessage = "âš ï¸ å½•éŸ³å¤±è´¥: \(error.localizedDescription)"
            onStartFailure?()
        }
    }
    
    public func pauseRecording() {
        guard state == .recording, let audioRecorder = audioRecorder else {
            logger.warning("Cannot pause - not recording or recorder is nil")
            return
        }
        
        // æš‚åœå½•éŸ³å¹¶ç¡®ä¿æ–‡ä»¶è¢«æ­£ç¡®å†™å…¥
        audioRecorder.pause()
        
        // é‡è¦ï¼šç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿æ–‡ä»¶è¢«æ­£ç¡®å†™å…¥
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) { [weak self] in
            guard let self = self else { return }
            
            self.state = .paused
            self.progressMessage = "Recording paused, processing..."
            self.logger.debug("Recording paused, preparing to transcribe current segment")
            
            // è·å–å½“å‰å½•éŸ³æ–‡ä»¶å¹¶è½¬å½•
            if let currentRecordingURL = self.recordingURL, FileManager.default.fileExists(atPath: currentRecordingURL.path) {
                // éªŒè¯æ–‡ä»¶å¤§å°
                do {
                    let fileAttributes = try FileManager.default.attributesOfItem(atPath: currentRecordingURL.path)
                    if let fileSize = fileAttributes[.size] as? Int {
                        let fileSizeKB = Double(fileSize) / 1024.0
                        self.logger.debug("Recording file size when paused: \(fileSizeKB) KB")
                        
                        if fileSize < 500 { // å°‘äº500å­—èŠ‚å¯èƒ½ä¸æ˜¯æœ‰æ•ˆéŸ³é¢‘
                            self.progressMessage = "Recording paused (segment too short to transcribe)"
                            self.logger.warning("Recording segment too short, skipping transcription")
                            return
                        }
                    }
                } catch {
                    self.logger.error("Cannot get file attributes: \(error.localizedDescription)")
                }
                
                // ä¸´æ—¶ä¿å­˜å½“å‰URLä»¥ä¾¿ç»§ç»­å½•éŸ³
                let currentURL = self.recordingURL
                
                // è½¬å½•å½“å‰ç‰‡æ®µ
                self.transcribeCurrentSegment(currentURL!)
            }
        }
    }
    
    public func stopRecording() {
        guard (state == .recording || state == .paused), let audioRecorder = audioRecorder else {
            logger.warning("Cannot stop - not recording/paused or recorder is nil")
            return
        }
        
        audioRecorder.stop()
        state = .processing
        
        // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç‰‡æ®µéƒ½å·²å¤„ç†
        let unprocessedParts = self.recordingParts.filter { !self.processedSegments.contains($0) }
        
        if unprocessedParts.isEmpty {
            logger.debug("Recording stopped - all segments already transcribed")
            progressMessage = "Processing complete, all content transcribed"
            finalizeTranscription()
            
            // æ¸…ç†
            recordingParts = []
            self.audioRecorder = nil
            return
        }
        
        progressMessage = "Processing recording..."
        logger.debug("Recording stopped, processing started (with \(unprocessedParts.count) unprocessed segments)")
        
        // å¤„ç†å½•éŸ³
        processRecordings()
    }
    
    public func setOutputDirectory(_ url: URL) {
        tunaSettings.transcriptionOutputDirectory = url
        logger.debug("Set output directory to \(url.path)")
    }
    
    public func setOutputFormat(_ format: String) {
        tunaSettings.transcriptionFormat = format
        logger.debug("Set output format to \(format)")
    }
    
    public func setApiKey(_ key: String) {
        // ä¿å­˜å¯†é’¥åˆ°Keychain
        do {
            try SecureStore.save(key: SecureStore.defaultAccount, value: key)
            logger.debug("API key updated and securely stored in Keychain")
            // åˆ·æ–°UIçŠ¶æ€
            NotificationCenter.default.post(name: .dictationAPIKeyUpdated, object: nil)
        } catch {
            logger.error("Failed to save API key to Keychain: \(error.localizedDescription)")
        }
        
        // ä¿æŒUserDefaultsçš„å‘åå…¼å®¹æ€§ï¼Œä½†åªå­˜å‚¨ä¸€ä¸ªç©ºå­—ç¬¦ä¸²è¡¨ç¤ºAPIå¯†é’¥å·²è®¾ç½®
        // ä¸å®é™…å­˜å‚¨å¯†é’¥å†…å®¹
        if !key.isEmpty {
            UserDefaults.standard.set(" ", forKey: "dictationApiKey") // åªå­˜å‚¨ä¸€ä¸ªç©ºæ ¼è¡¨ç¤ºæœ‰å¯†é’¥
        } else {
            UserDefaults.standard.removeObject(forKey: "dictationApiKey")
        }
    }
    
    public func getDocumentsDirectory() -> URL {
        return tunaSettings.transcriptionOutputDirectory ?? FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
    }
    
    // æ·»åŠ è·å–å½“å‰è½¬å½•å†…å®¹çš„æ–¹æ³•ï¼Œç”¨äºåœ¨ç”¨æˆ·ç¼–è¾‘åæ¯”è¾ƒå·®å¼‚
    public func getPreviousTranscription() -> String? {
        return self.transcribedText
    }
    
    // MARK: - è·å–å½“å‰è®¾ç½®
    
    // è·å–å½“å‰è¾“å‡ºæ ¼å¼
    public var outputFormat: String {
        return tunaSettings.transcriptionFormat
    }
    
    // è·å–å½“å‰è¾“å‡ºç›®å½•
    public var outputDirectory: URL? {
        return tunaSettings.transcriptionOutputDirectory
    }
    
    // MARK: - Private Methods
    
    private func setupRecordingSession() {
#if os(iOS)
        // iOSç‰ˆæœ¬ - ä½¿ç”¨AVAudioSession
        // æ£€æŸ¥éº¦å…‹é£æƒé™
        let audioSession = AVAudioSession.sharedInstance()
        audioSession.requestRecordPermission { [weak self] allowed in
            guard let self = self else { return }
            
            DispatchQueue.main.async {
                if !allowed {
                    self.progressMessage = "éº¦å…‹é£è®¿é—®æƒé™è¢«æ‹’ç»"
                    self.logger.error("éº¦å…‹é£è®¿é—®æƒé™è¢«æ‹’ç»")
                    return
                }
                
                self.logger.debug("éº¦å…‹é£è®¿é—®æƒé™å·²æˆäºˆ")
            }
        }
#else
        // macOSç‰ˆæœ¬ - ä½¿ç”¨AVCaptureDevice
        if #available(macOS 10.14, *) {
            AVCaptureDevice.requestAccess(for: .audio) { [weak self] allowed in
                guard let self = self else { return }
                
                DispatchQueue.main.async {
                    if !allowed {
                        self.progressMessage = "éº¦å…‹é£è®¿é—®æƒé™è¢«æ‹’ç»"
                        self.logger.error("éº¦å…‹é£è®¿é—®æƒé™è¢«æ‹’ç»")
                        return
                    }
                    
                    self.logger.debug("éº¦å…‹é£è®¿é—®æƒé™å·²æˆäºˆ")
                }
            }
        } else {
            // æ—§ç‰ˆmacOSé»˜è®¤æœ‰æƒé™
            logger.debug("macOS 10.14ä»¥ä¸‹ç‰ˆæœ¬æ— æ³•æ£€æŸ¥éº¦å…‹é£æƒé™ï¼Œé»˜è®¤ç»§ç»­")
        }
#endif
    }
    
    private func processRecordings() {
        guard !self.recordingParts.isEmpty else {
            state = .idle
            progressMessage = "No recording files"
            logger.warning("No recordings to process")
            return
        }
        
        // è¿‡æ»¤å‡ºæœªå¤„ç†çš„ç‰‡æ®µ
        let unprocessedParts = self.recordingParts.filter { !self.processedSegments.contains($0) }
        
        if unprocessedParts.isEmpty {
            // æ‰€æœ‰ç‰‡æ®µéƒ½å·²è½¬å½•ï¼Œç›´æ¥å®Œæˆ
            logger.debug("All segments already transcribed, skipping duplicate processing")
            finalizeTranscription()
            
            // æ¸…ç†
            self.recordingParts = []
            self.audioRecorder = nil
            return
        }
        
        logger.debug("Processing \(unprocessedParts.count) untranscribed segments, out of \(self.recordingParts.count) total segments")
        progressMessage = "Processing new recording parts..."
        
        // å¦‚æœåªæœ‰ä¸€ä¸ªæœªå¤„ç†çš„ç‰‡æ®µï¼Œç›´æ¥ä½¿ç”¨å®ƒ
        if unprocessedParts.count == 1, let audioURL = unprocessedParts.first {
            transcribeAudio(audioURL)
            return
        }
        
        // ä½¿ç”¨é€’å½’å‡½æ•°å¤„ç†æœªè½¬å½•çš„ç‰‡æ®µ
        transcribeSegmentsSequentially(unprocessedParts, currentIndex: 0, accumulator: self.transcribedText)
    }
    
    // ä¾æ¬¡å¤„ç†å¤šä¸ªå½•éŸ³ç‰‡æ®µ
    private func transcribeSegmentsSequentially(_ segments: [URL], currentIndex: Int, accumulator: String) {
        // åŸºç¡€æƒ…å†µï¼šæ‰€æœ‰ç‰‡æ®µéƒ½å·²å¤„ç†
        if currentIndex >= segments.count {
            // å…¨éƒ¨å¤„ç†å®Œæˆï¼Œæ›´æ–°çŠ¶æ€
            self.transcribedText = accumulator
            finalizeTranscription()
            
            // æ¸…ç†
            self.recordingParts = []
            self.audioRecorder = nil
            return
        }
        
        // è·å–å½“å‰ç‰‡æ®µ
        let currentSegment = segments[currentIndex]
        
        // å¦‚æœè¯¥ç‰‡æ®µå·²ç»è¢«å¤„ç†è¿‡ï¼Œç›´æ¥è·³åˆ°ä¸‹ä¸€ä¸ª
        if self.processedSegments.contains(currentSegment) {
            logger.debug("ç‰‡æ®µå·²å¤„ç†è¿‡ï¼Œè·³è¿‡: \(currentSegment.path)")
            transcribeSegmentsSequentially(segments, currentIndex: currentIndex + 1, accumulator: accumulator)
            return
        }
        
        progressMessage = "Transcribing segment \(currentIndex + 1)/\(segments.count)..."
        logger.debug("Transcribing segment \(currentIndex + 1)/\(segments.count): \(currentSegment.path)")
        
        // è½¬å½•å½“å‰ç‰‡æ®µ
        callWhisperAPI(audioURL: currentSegment) { [weak self] result in
            guard let self = self else { return }
            
            DispatchQueue.main.async {
                switch result {
                case .success(let segmentText):
                    // å°†å½“å‰ç‰‡æ®µçš„è½¬å½•ç»“æœæ·»åŠ åˆ°ç´¯åŠ å™¨
                    var newAccumulator = accumulator
                    if !newAccumulator.isEmpty && !segmentText.isEmpty {
                        newAccumulator += "\n"
                    }
                    newAccumulator += segmentText
                    
                    // æ ‡è®°è¯¥ç‰‡æ®µå·²å¤„ç†
                    self.processedSegments.insert(currentSegment)
                    
                    // é€’å½’å¤„ç†ä¸‹ä¸€ä¸ªç‰‡æ®µ
                    self.transcribeSegmentsSequentially(segments, currentIndex: currentIndex + 1, accumulator: newAccumulator)
                    
                case .failure(let error):
                    self.logger.error("Failed to transcribe segment \(currentIndex + 1): \(error.localizedDescription)")
                    
                    // å³ä½¿å½“å‰ç‰‡æ®µå¤±è´¥ï¼Œä¹Ÿç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªç‰‡æ®µ
                    self.transcribeSegmentsSequentially(segments, currentIndex: currentIndex + 1, accumulator: accumulator)
                }
            }
        }
    }
    
    private func transcribeAudio(_ audioURL: URL) {
        // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
        guard !apiKey.isEmpty else {
            state = .idle
            progressMessage = "Please set API key in settings"
            logger.error("API key not set")
            
            // å‘é€é€šçŸ¥ï¼Œè¡¨ç¤ºç¼ºå°‘APIå¯†é’¥
            DispatchQueue.main.async {
                NotificationCenter.default.post(
                    name: .dictationAPIKeyMissing,
                    object: nil
                )
            }
            return
        }
        
        // å¦‚æœå·²ç»å¤„ç†è¿‡æ­¤æ–‡ä»¶ï¼Œè·³è¿‡é‡å¤è½¬å½•
        if processedSegments.contains(audioURL) {
            logger.debug("æ–‡ä»¶å·²è½¬å½•è¿‡ï¼Œè·³è¿‡: \(audioURL.path)")
            finalizeTranscription()
            
            // æ¸…ç†
            self.recordingParts = []
            self.audioRecorder = nil
            return
        }
        
        progressMessage = "Transcribing audio..."
        logger.debug("Transcribing audio from \(audioURL.path)")
        
        // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å¯è¯»
        guard FileManager.default.fileExists(atPath: audioURL.path) else {
            state = .idle
            progressMessage = "Cannot read audio file"
            logger.error("Failed to read audio file")
            return
        }
        
        // è°ƒç”¨Whisper API
        callWhisperAPI(audioURL: audioURL) { [weak self] result in
            guard let self = self else { return }
            
            DispatchQueue.main.async {
                switch result {
                case .success(let transcribedText):
                    // è®¾ç½®è½¬å½•æ–‡æœ¬ï¼Œä½¿ç”¨APIè¿”å›çš„å®é™…å†…å®¹
                    self.transcribedText = transcribedText
                    
                    // æ ‡è®°è¯¥æ–‡ä»¶å·²å¤„ç†
                    self.processedSegments.insert(audioURL)
                    
                    // æ›´æ–°çŠ¶æ€å¹¶è®¾ç½®æ¶ˆæ¯
                    self.finalizeTranscription()
                    self.logger.debug("Transcription completed successfully")
                    
                case .failure(let error):
                    self.progressMessage = "Transcription failed: \(error.localizedDescription)"
                    self.logger.error("Transcription failed: \(error.localizedDescription)")
                    self.state = .idle
                }
                
                // æ¸…ç†
                self.recordingParts = []
                self.audioRecorder = nil
            }
        }
    }
    
    // è½¬å½•å½“å‰å½•éŸ³ç‰‡æ®µï¼Œä½†ä¿æŒå½•éŸ³çŠ¶æ€
    private func transcribeCurrentSegment(_ audioURL: URL) {
        // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
        guard !apiKey.isEmpty else {
            progressMessage = "Please set API key in settings"
            logger.error("API key not set")
            
            // å‘é€é€šçŸ¥ï¼Œè¡¨ç¤ºç¼ºå°‘APIå¯†é’¥
            DispatchQueue.main.async {
                NotificationCenter.default.post(
                    name: .dictationAPIKeyMissing,
                    object: nil
                )
            }
            return
        }
        
        progressMessage = "Transcribing current segment..."
        logger.debug("Transcribing current segment from \(audioURL.path)")
        
        // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å¯è¯»
        guard FileManager.default.fileExists(atPath: audioURL.path) else {
            progressMessage = "Cannot read audio file"
            logger.error("Failed to read audio file")
            return
        }
        
        // è°ƒç”¨Whisper APIè½¬å½•å½“å‰ç‰‡æ®µ
        callWhisperAPI(audioURL: audioURL) { [weak self] result in
            guard let self = self else { return }
            
            DispatchQueue.main.async {
                switch result {
                case .success(let segmentText):
                    // è¿½åŠ è½¬å½•æ–‡æœ¬ï¼Œè€Œä¸æ˜¯æ›¿æ¢
                    if self.transcribedText.isEmpty {
                        self.transcribedText = segmentText
                    } else {
                        // å…ˆå¤‡ä»½å½“å‰å€¼ï¼Œç„¶åè®¾ç½®æ–°å€¼ä»¥ç¡®ä¿UIæ›´æ–°
                        let newText = self.transcribedText + "\n" + segmentText
                        self.transcribedText = ""
                        self.transcribedText = newText
                    }
                    
                    // æ ‡è®°æ­¤ç‰‡æ®µå·²å¤„ç†
                    self.processedSegments.insert(audioURL)
                    
                    // æ›´æ–°çŠ¶æ€æ¶ˆæ¯
                    self.progressMessage = "Paused - partial content transcribed"
                    self.logger.debug("Current segment transcribed successfully")
                    
                    // æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è‡ªåŠ¨å¤åˆ¶åŠŸèƒ½ï¼Œå¦‚æœæ˜¯åˆ™å¤åˆ¶å½“å‰è½¬å½•æ–‡æœ¬åˆ°å‰ªè´´æ¿
                    if self.tunaSettings.autoCopyTranscriptionToClipboard && !self.transcribedText.isEmpty {
                        let pasteboard = NSPasteboard.general
                        pasteboard.clearContents()
                        pasteboard.setString(self.transcribedText, forType: .string)
                        self.logger.debug("Auto-copied segment transcription to clipboard")
                        self.progressMessage = "Paused - content transcribed and copied"
                    }
                    
                case .failure(let error):
                    self.progressMessage = "Partial transcription failed: \(error.localizedDescription)"
                    self.logger.error("Segment transcription failed: \(error.localizedDescription)")
                }
            }
        }
    }
    
    // è°ƒç”¨OpenAI Whisper API
    private func callWhisperAPI(audioURL: URL, completion: @escaping (Result<String, Error>) -> Void) {
        // æ£€æŸ¥APIå¯†é’¥
        guard !apiKey.isEmpty else {
            completion(.failure(DictationError.noAPIKey))
            
            // å‘é€é€šçŸ¥ï¼Œè¡¨ç¤ºç¼ºå°‘APIå¯†é’¥
            DispatchQueue.main.async {
                NotificationCenter.default.post(
                    name: .dictationAPIKeyMissing,
                    object: nil
                )
            }
            return
        }
        
        // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¹¶è·å–æ–‡ä»¶å¤§å°
        guard let audioData = try? Data(contentsOf: audioURL) else {
            completion(.failure(DictationError.audioFileReadError))
            return
        }
        
        // è®°å½•éŸ³é¢‘æ–‡ä»¶å¤§å°ï¼Œç”¨äºè°ƒè¯•
        let fileSizeBytes = audioData.count
        let fileSizeKB = Double(fileSizeBytes) / 1024.0
        logger.debug("Audio file size: \(fileSizeKB) KB")
        
        // æ£€æŸ¥æ–‡ä»¶å¤§å° - Whisper APIå¯¹æ–‡ä»¶å¤§å°æœ‰é™åˆ¶
        if fileSizeBytes < 1024 { // å°‘äº1KBï¼Œå¯èƒ½å¤ªå°
            logger.warning("Audio file may be too small (\(fileSizeKB) KB)")
            // ä»ç„¶å°è¯•å‘é€ï¼Œä½†è®°å½•è­¦å‘Š
        }
        
        if fileSizeBytes > 25 * 1024 * 1024 { // å¤§äº25MB
            completion(.failure(NSError(domain: "com.tuna.error", code: 413, userInfo: [NSLocalizedDescriptionKey: "Audio file too large: \(fileSizeKB) KB, exceeds API limit"])))
            return
        }
        
        // åˆ›å»ºboundaryç”¨äºmultipartè¯·æ±‚
        let boundary = "Boundary-\(UUID().uuidString)"
        
        // è®¾ç½®API URL
        guard let url = URL(string: "https://api.openai.com/v1/audio/transcriptions") else {
            completion(.failure(NSError(domain: "com.tuna.error", code: 500, userInfo: [NSLocalizedDescriptionKey: "Invalid API URL"])))
            return
        }
        
        // åˆ›å»ºè¯·æ±‚
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.addValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        request.addValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")
        
        // åˆ›å»ºè¯·æ±‚ä½“
        var httpBody = Data()
        
        // æ·»åŠ æ¨¡å‹
        httpBody.append("--\(boundary)\r\n".data(using: .utf8)!)
        httpBody.append("Content-Disposition: form-data; name=\"model\"\r\n\r\n".data(using: .utf8)!)
        httpBody.append("whisper-1\r\n".data(using: .utf8)!)
        
        // æ·»åŠ æ–‡ä»¶
        httpBody.append("--\(boundary)\r\n".data(using: .utf8)!)
        httpBody.append("Content-Disposition: form-data; name=\"file\"; filename=\"audio.wav\"\r\n".data(using: .utf8)!)
        httpBody.append("Content-Type: audio/wav\r\n\r\n".data(using: .utf8)!)
        httpBody.append(audioData)
        httpBody.append("\r\n".data(using: .utf8)!)
        
        // æ·»åŠ å“åº”æ ¼å¼
        httpBody.append("--\(boundary)\r\n".data(using: .utf8)!)
        httpBody.append("Content-Disposition: form-data; name=\"response_format\"\r\n\r\n".data(using: .utf8)!)
        httpBody.append("json\r\n".data(using: .utf8)!)
        
        // å¦‚æœç”¨æˆ·æŒ‡å®šäº†è¯­è¨€ï¼Œåˆ™æ·»åŠ languageå‚æ•°ï¼Œå¦åˆ™è®©APIè‡ªåŠ¨æ£€æµ‹
        let selectedLanguage = TunaSettings.shared.transcriptionLanguage
        if !selectedLanguage.isEmpty {
            httpBody.append("--\(boundary)\r\n".data(using: .utf8)!)
            httpBody.append("Content-Disposition: form-data; name=\"language\"\r\n\r\n".data(using: .utf8)!)
            httpBody.append("\(selectedLanguage)\r\n".data(using: .utf8)!)
            logger.debug("Using specified language for transcription: \(selectedLanguage)")
        } else {
            // ä¸æŒ‡å®šè¯­è¨€ï¼Œè®©APIè‡ªåŠ¨æ£€æµ‹
            // Whisper APIä¼šæ ¹æ®éŸ³é¢‘å†…å®¹è‡ªåŠ¨æ£€æµ‹è¯­è¨€
            logger.debug("Using automatic language detection for transcription")
        }
        
        // æ·»åŠ æ¸©åº¦å‚æ•°ï¼ˆå¯ä»¥è°ƒæ•´æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ï¼‰
        httpBody.append("--\(boundary)\r\n".data(using: .utf8)!)
        httpBody.append("Content-Disposition: form-data; name=\"temperature\"\r\n\r\n".data(using: .utf8)!)
        httpBody.append("0.0\r\n".data(using: .utf8)!) // ä½¿ç”¨æœ€ä½æ¸©åº¦ï¼Œæœ€ç¡®å®šçš„è½¬å½•
        
        // ç»“æŸboundary
        httpBody.append("--\(boundary)--\r\n".data(using: .utf8)!)
        
        // è®¾ç½®è¯·æ±‚ä½“
        request.httpBody = httpBody
        
        // è®°å½•è¯·æ±‚è¯¦æƒ…ç”¨äºè°ƒè¯•
        logger.debug("API request total size: \(httpBody.count) bytes")
        logger.debug("Audio file URL: \(audioURL.path)")
        
        // å‘é€è¯·æ±‚
        let task = URLSession.shared.dataTask(with: request) { [weak self] data, response, error in
            guard let self = self else { return }
            
            if let error = error {
                self.logger.error("Network error: \(error.localizedDescription)")
                completion(.failure(error))
                return
            }
            
            guard let httpResponse = response as? HTTPURLResponse else {
                self.logger.error("Invalid HTTP response")
                completion(.failure(NSError(domain: "com.tuna.error", code: 500, userInfo: [NSLocalizedDescriptionKey: "Invalid HTTP response"])))
                return
            }
            
            // è®°å½•å“åº”çŠ¶æ€ç 
            self.logger.debug("API response status code: \(httpResponse.statusCode)")
            
            // æ£€æŸ¥çŠ¶æ€ç 
            if httpResponse.statusCode != 200 {
                var errorMessage = "API error: Status code \(httpResponse.statusCode)"
                
                if let data = data {
                    // å°è¯•è§£æè¯¦ç»†é”™è¯¯ä¿¡æ¯
                    if let responseString = String(data: data, encoding: .utf8) {
                        self.logger.error("API error response: \(responseString)")
                        errorMessage = "API error(\(httpResponse.statusCode)): \(responseString)"
                        
                        // å°è¯•è§£æä¸ºJSONè·å–æ›´è¯¦ç»†çš„é”™è¯¯
                        if let errorJson = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
                           let errorObject = errorJson["error"] as? [String: Any],
                           let errorMessage = errorObject["message"] as? String {
                            self.logger.error("API error details: \(errorMessage)")
                            completion(.failure(NSError(domain: "com.tuna.error", code: httpResponse.statusCode, userInfo: [NSLocalizedDescriptionKey: "API error: \(errorMessage)"])))
                            return
                        }
                    }
                }
                
                // è‹¥æ— æ³•è§£æè¯¦ç»†é”™è¯¯ï¼Œè¿”å›åŸºæœ¬é”™è¯¯
                completion(.failure(NSError(domain: "com.tuna.error", code: httpResponse.statusCode, userInfo: [NSLocalizedDescriptionKey: errorMessage])))
                return
            }
            
            // è§£æå“åº”
            guard let data = data else {
                self.logger.error("API did not return data")
                completion(.failure(NSError(domain: "com.tuna.error", code: 500, userInfo: [NSLocalizedDescriptionKey: "No data returned"])))
                return
            }
            
            do {
                if let responseString = String(data: data, encoding: .utf8) {
                    self.logger.debug("API raw response: \(responseString)")
                }
                
                if let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
                   let text = json["text"] as? String {
                    self.logger.debug("API returned transcription: \(text)")
                    completion(.success(text))
                } else {
                    self.logger.error("Could not parse API response to expected format")
                    completion(.failure(NSError(domain: "com.tuna.error", code: 500, userInfo: [NSLocalizedDescriptionKey: "Could not parse API response"])))
                }
            } catch {
                self.logger.error("Failed to parse API response: \(error.localizedDescription)")
                completion(.failure(error))
            }
        }
        
        // å¯åŠ¨ä»»åŠ¡
        task.resume()
        
        logger.debug("API request sent")
    }
    
    // è®¾ç½®å½•éŸ³ä¸­çŠ¶æ€ä¸ºå¤„ç†ä¸­
    func finalizeTranscription() {
        state = .idle
        if transcribedText.isEmpty {
            progressMessage = "Transcription failed, no text result"
        } else {
            progressMessage = "Transcription completed - click Save to save"
            
            // æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è‡ªåŠ¨å¤åˆ¶åŠŸèƒ½ï¼Œå¦‚æœæ˜¯åˆ™å¤åˆ¶åˆ°å‰ªè´´æ¿
            if TunaSettings.shared.autoCopyTranscriptionToClipboard && !transcribedText.isEmpty {
                let pasteboard = NSPasteboard.general
                pasteboard.clearContents()
                pasteboard.setString(transcribedText, forType: .string)
                logger.debug("Auto-copied transcription to clipboard")
                progressMessage = "Transcription completed and copied to clipboard"
            }
        }
    }
} 