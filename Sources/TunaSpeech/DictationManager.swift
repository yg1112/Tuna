import AVFoundation
import Combine
import Foundation
import os.log
import SwiftUI
import TunaAudio
import TunaTypes

/// Manages audio dictation and transcription
@MainActor
public class DictationManager: NSObject, DictationManagerProtocol {
    @MainActor public static let shared = DictationManager(
        providerType: WhisperProvider.self,
        secureStore: SecureStore.shared,
        notifierType: Notifier.self
    )

    // å…è®¸æ›¿æ¢å•ä¾‹ä»¥ä¾¿æµ‹è¯•
    #if DEBUG
    public static func createForTesting(nowProvider: NowProvider = RealNowProvider())
    -> DictationManager {
        let manager = DictationManager(nowProvider: nowProvider)
        return manager
    }

    // ç”¨äºæµ‹è¯•çš„é‡ç½®æ–¹æ³•
    public func reset() {
        self._state = DictationState()
        self._progressMessage = ""
        self._transcribedText = ""
        self.recordingParts = []
        self.processedSegments = []
    }
    #endif

    // MARK: - Dependencies
    public let providerType: SpeechProviderProtocol.Type
    public let secureStore: any SecureStoreProtocol
    public let notifierType: any NotifierProtocol.Type

    // MARK: - Init
    public init(
        providerType: SpeechProviderProtocol.Type = WhisperProvider.self,
        secureStore: any SecureStoreProtocol = SecureStore.shared,
        notifierType: any NotifierProtocol.Type = Notifier.self,
        nowProvider: NowProvider = RealNowProvider(),
        uuidProvider: UUIDProvider = RealUUIDProvider()
    ) {
        self.providerType = providerType
        self.secureStore = secureStore
        self.notifierType = notifierType
        self.nowProvider = nowProvider
        self.uuidProvider = uuidProvider
        super.init()
        self.setupRecordingSession()
    }

    // MARK: - Protocol Properties
    @Published private var _state = DictationState()
    @Published private var _progressMessage: String = ""
    @Published private var _transcribedText: String = ""

    public var state: DictationState {
        get {
            self._state
        }
        set {
            self._state = newValue
        }
    }

    public var progressMessage: String {
        get {
            self._progressMessage
        }
        set {
            self._progressMessage = newValue
        }
    }

    public var transcribedText: String {
        get {
            self._transcribedText
        }
        set {
            self._transcribedText = newValue
        }
    }

    public var isRecording: Bool {
        self._state.isRecording
    }

    public var isPaused: Bool {
        self._state.isPaused
    }

    public var breathingAnimation: Bool {
        self._state.breathingAnimation
    }

    // MARK: - Private Properties
    private let logger = Logger(
        subsystem: Bundle.main.bundleIdentifier!,
        category: "DictationManager"
    )
    private let tunaSettings = TunaSettings.shared
    private let nowProvider: NowProvider
    private let uuidProvider: UUIDProvider
    private var tempDirectory: URL?

    // æ·»åŠ å¯åŠ¨å¤±è´¥å›è°ƒ
    public var onStartFailure: (() -> Void)?

    // å½•éŸ³ç›¸å…³
    private var audioRecorder: AVAudioRecorder?
    private var recordingURL: URL?
    private var recordingParts: [URL] = []
    private var processedSegments: Set<URL> = []

    // ä¿®æ”¹APIå¯†é’¥è·å–æ–¹å¼ï¼Œä½¿ç”¨SecureStore
    private var apiKey: String {
        do {
            if let data = try secureStore.load(
                key: SecureStore.defaultAccount,
                account: SecureStore.defaultAccount
            ),
                let str = String(data: Data(data.utf8), encoding: .utf8)
            {
                return str
            }
            return ""
        } catch {
            self.logger
                .error("Failed to get API key from Keychain: \(error.localizedDescription)")
            return ""
        }
    }

    // MARK: - Public Methods

    // æ·»åŠ toggleæ–¹æ³•ï¼Œæ ¹æ®å½“å‰çŠ¶æ€åˆ‡æ¢å½•éŸ³çŠ¶æ€
    public func toggle() async {
        let state = self.state.state
        switch state {
            case .idle:
                await self.startRecording()
            case .recording:
                await self.pauseRecording()
            case .paused:
                await self.continueRecording()
            case .processing:
                self.logger.notice("Cannot toggle - processing")
            case .error:
                self.logger.notice("Cannot toggle - error")
        }
    }

    public func resumeRecording() async {
        let state = self.state.state
        if state == .paused {
            await self.continueRecording()
        }
    }

    public func startRecording() async {
        self.logger.notice("å¼€å§‹å½•éŸ³...")

        // å¦‚æœå·²ç»åœ¨å½•éŸ³ï¼Œç›´æ¥è¿”å›
        if self.isRecording {
            self.logger.notice("å·²ç»åœ¨å½•éŸ³ä¸­ï¼Œå¿½ç•¥è¯·æ±‚")
            return
        }

        // è®¾ç½®çŠ¶æ€æ¶ˆæ¯
        self.progressMessage = "å‡†å¤‡å½•éŸ³..."
        print("ğŸ™ DictationManager.startRecording() è¢«è°ƒç”¨ï¼Œå½“å‰çŠ¶æ€: \(self.state)")

        // ç¡®ä¿éŸ³é¢‘ä¼šè¯å·²è®¾ç½®
        self.setupRecordingSession()

        // å®é™…å¯åŠ¨å½•éŸ³é€»è¾‘
        await self.continueRecording()
    }

    private func continueRecording() async {
        Logger(subsystem: "ai.tuna", category: "Shortcut")
            .notice("[R] startRecording() actually called")
        self.sendDebugNotification(message: "å¼€å§‹æ‰§è¡Œå½•éŸ³æµç¨‹")

        // ç¡®ä¿æˆ‘ä»¬å¤„äºæ­£ç¡®çš„çŠ¶æ€
        let state = self.state.state
        guard state == .idle || state == .paused else {
            self.logger.warning("Cannot start recording - wrong state")
            self.sendDebugNotification(message: "æ— æ³•å¼€å§‹å½•éŸ³ - çŠ¶æ€é”™è¯¯: \(self.state)")
            return
        }

        // å¦‚æœå¤„äºæš‚åœçŠ¶æ€ï¼Œåˆ›å»ºæ–°çš„å½•éŸ³ç‰‡æ®µ
        if state == .paused, self.audioRecorder != nil {
            // ä¿å­˜å·²æœ‰çš„audioRecorderç”¨äºæ¸…ç†
            let oldRecorder = self.audioRecorder

            // åˆ›å»ºæ–°çš„å½•éŸ³æ–‡ä»¶
            let fileName = "dictation_\(nowProvider.now().timeIntervalSince1970).wav"
            recordingURL = self.tempDirectory?.appendingPathComponent(fileName)

            guard let recordingURL else {
                self.logger.error("Failed to create recording URL")
                self.progressMessage = "âš ï¸ æ— æ³•åˆ›å»ºå½•éŸ³æ–‡ä»¶"
                self.onStartFailure?()
                return
            }

            // è®¾ç½®å½•éŸ³å‚æ•° - ä½¿ç”¨æ›´ç®€å•çš„WAVæ ¼å¼ï¼Œæ›´å®¹æ˜“è¢«Whisper APIå¤„ç†
            let settings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatLinearPCM), // ä½¿ç”¨æ— æŸPCMæ ¼å¼
                AVSampleRateKey: 16000.0, // 16kHzé‡‡æ ·ç‡ï¼ŒWhisperæ¨¡å‹æ¥å—è¿™ä¸ªé‡‡æ ·ç‡
                AVNumberOfChannelsKey: 1, // å•å£°é“
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue,
                AVLinearPCMBitDepthKey: 16, // 16ä½
                AVLinearPCMIsBigEndianKey: false,
                AVLinearPCMIsFloatKey: false,
            ]

            do {
                self.audioRecorder = try AVAudioRecorder(url: recordingURL, settings: settings)
                self.audioRecorder?.delegate = nil
                self.audioRecorder?.record()

                // æ·»åŠ åˆ°å½•éŸ³éƒ¨åˆ†åˆ—è¡¨
                self.recordingParts.append(recordingURL)

                // åœæ­¢å¹¶é‡Šæ”¾æ—§çš„å½•éŸ³å™¨
                oldRecorder?.stop()

                // æ›´æ–°çŠ¶æ€
                var newState = self.state
                newState.state = .recording
                self.state = newState
                self.progressMessage = "ğŸ™ æ­£åœ¨å½•éŸ³..."

                // è§¦å‘UIæ›´æ–°
                let current = self.transcribedText
                self.transcribedText = ""
                self.transcribedText = current

                self.logger.debug("Created new recording segment at \(recordingURL.path)")
                self.logger.notice("state -> recording (continue)")
            } catch {
                self.logger.error("Failed to continue recording: \(error.localizedDescription)")
                self.progressMessage = "âš ï¸ å½•éŸ³å¤±è´¥: \(error.localizedDescription)"

                // æ¢å¤æ—§çš„å½•éŸ³å™¨çŠ¶æ€
                self.audioRecorder = oldRecorder
                self.onStartFailure?()
            }

            return
        }

        // å¦‚æœä¸æ˜¯ä»æš‚åœçŠ¶æ€ç»§ç»­ï¼Œåˆ™æ¸…é™¤å·²æœ‰çš„è½¬å½•å†…å®¹å¹¶å¼€å§‹æ–°å½•éŸ³
        if state == .idle {
            // æ¸…é™¤è½¬å½•æ–‡æœ¬ä»¥å¼€å§‹æ–°å½•éŸ³
            self.transcribedText = ""
            self.recordingParts = []
            self.processedSegments = [] // é‡ç½®å·²å¤„ç†ç‰‡æ®µè®°å½•
        }

        // åˆ›å»ºæ–°çš„å½•éŸ³æ–‡ä»¶
        let fileName = "dictation_\(nowProvider.now().timeIntervalSince1970).wav"
        recordingURL = self.tempDirectory?.appendingPathComponent(fileName)

        guard let recordingURL else {
            self.logger.error("Failed to create recording URL")
            self.progressMessage = "âš ï¸ æ— æ³•åˆ›å»ºå½•éŸ³æ–‡ä»¶"
            self.onStartFailure?()
            return
        }

        // è®¾ç½®å½•éŸ³å‚æ•°
        let settings: [String: Any] = [
            AVFormatIDKey: Int(kAudioFormatLinearPCM),
            AVSampleRateKey: 16000.0,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue,
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsBigEndianKey: false,
            AVLinearPCMIsFloatKey: false,
        ]

        do {
            self.audioRecorder = try AVAudioRecorder(url: recordingURL, settings: settings)
            self.audioRecorder?.delegate = nil
            self.audioRecorder?.record()

            // æ·»åŠ åˆ°å½•éŸ³éƒ¨åˆ†åˆ—è¡¨
            self.recordingParts.append(recordingURL)

            var newState = self.state
            newState.state = .recording
            self.state = newState
            self.progressMessage = "ğŸ™ æ­£åœ¨å½•éŸ³..."
            self.logger.debug("Started new recording at \(recordingURL.path)")
            self.logger.notice("state -> recording (new)")
        } catch {
            self.logger.error("Failed to start recording: \(error.localizedDescription)")
            self.progressMessage = "âš ï¸ å½•éŸ³å¤±è´¥: \(error.localizedDescription)"
            self.onStartFailure?()
        }
    }

    public func pauseRecording() async {
        guard self.state.state == .recording, let audioRecorder else {
            self.logger.warning("Cannot pause - not recording or recorder is nil")
            return
        }

        // æš‚åœå½•éŸ³å¹¶ç¡®ä¿æ–‡ä»¶è¢«æ­£ç¡®å†™å…¥
        audioRecorder.pause()

        // é‡è¦ï¼šç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿æ–‡ä»¶è¢«æ­£ç¡®å†™å…¥
        Task { @MainActor in
            try? await Task.sleep(nanoseconds: 500_000_000)
            self.notifierType.post(NSNotification.Name.fileSelectionEnded, object: nil)
        }

        var newState = self.state
        newState.state = .paused
        self.state = newState
        self.progressMessage = "Recording paused, processing..."
        self.logger.debug("Recording paused, preparing to transcribe current segment")

        // è·å–å½“å‰å½•éŸ³æ–‡ä»¶å¹¶è½¬å½•
        if let currentRecordingURL = recordingURL,
           FileManager.default.fileExists(atPath: currentRecordingURL.path)
        {
            // éªŒè¯æ–‡ä»¶å¤§å°
            do {
                let fileAttributes = try FileManager.default
                    .attributesOfItem(atPath: currentRecordingURL.path)
                if let fileSize = fileAttributes[.size] as? Int {
                    let fileSizeKB = Double(fileSize) / 1024.0
                    self.logger.debug("Recording file size when paused: \(fileSizeKB) KB")

                    if fileSize < 500 { // å°‘äº500å­—èŠ‚å¯èƒ½ä¸æ˜¯æœ‰æ•ˆéŸ³é¢‘
                        self.progressMessage =
                            "Recording paused (segment too short to transcribe)"
                        self.logger
                            .warning("Recording segment too short, skipping transcription")
                        return
                    }
                }
            } catch {
                self.logger.error("Cannot get file attributes: \(error.localizedDescription)")
            }

            // ä¸´æ—¶ä¿å­˜å½“å‰URLä»¥ä¾¿ç»§ç»­å½•éŸ³
            let currentURL = self.recordingURL

            // è½¬å½•å½“å‰ç‰‡æ®µ
            await self.transcribeCurrentSegment(currentURL!)
        }
    }

    public func stopRecording() async {
        let state = self.state.state
        guard state == .recording || state == .paused, let audioRecorder else {
            self.logger.warning("Cannot stop - not recording/paused or recorder is nil")
            return
        }

        audioRecorder.stop()
        var newState = self.state
        newState.state = .processing
        self.state = newState

        // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç‰‡æ®µéƒ½å·²å¤„ç†
        let unprocessedParts = self.recordingParts.filter { !self.processedSegments.contains($0) }

        if unprocessedParts.isEmpty {
            self.logger.debug("Recording stopped - all segments already transcribed")
            self.progressMessage = "Processing complete, all content transcribed"
            await self.finalizeTranscription()

            // æ¸…ç†
            self.recordingParts = []
            self.audioRecorder = nil
            return
        }

        self.progressMessage = "Processing recording..."
        self.logger
            .debug(
                "Processing \(unprocessedParts.count) untranscribed segments, out of \(self.recordingParts.count) total segments"
            )

        // å¤„ç†å½•éŸ³
        await self.processRecordings()
    }

    public func setOutputDirectory(_ url: URL) {
        self.tunaSettings.transcriptionOutputDirectory = url
        self.logger.debug("Set output directory to \(url.path)")
    }

    public func setOutputFormat(_ format: String) {
        self.tunaSettings.transcriptionFormat = format
        self.logger.debug("Set output format to \(format)")
    }

    public func setApiKey(_ key: String) async {
        // ä¿å­˜å¯†é’¥åˆ°Keychain
        do {
            try self.secureStore.set(
                value: key.data(using: .utf8)!,
                forKey: SecureStore.defaultAccount,
                account: SecureStore.defaultAccount
            )
            self.logger.debug("API key updated and securely stored in Keychain")
            // åˆ·æ–°UIçŠ¶æ€
            self.notifierType.post(NSNotification.Name.dictationAPIKeyUpdated, object: nil)
        } catch {
            self.logger.error("Failed to save API key to Keychain: \(error.localizedDescription)")
            self.notifierType.post(NSNotification.Name.dictationAPIKeyMissing, object: nil)
        }
    }

    public func getDocumentsDirectory() -> URL {
        self.tunaSettings.transcriptionOutputDirectory ?? FileManager.default.urls(
            for: .documentDirectory,
            in: .userDomainMask
        )[0]
    }

    // æ·»åŠ è·å–å½“å‰è½¬å½•å†…å®¹çš„æ–¹æ³•ï¼Œç”¨äºåœ¨ç”¨æˆ·ç¼–è¾‘åæ¯”è¾ƒå·®å¼‚
    public func getPreviousTranscription() async -> String? {
        await Task { @MainActor in self._transcribedText }.value
    }

    // MARK: - è·å–å½“å‰è®¾ç½®

    // è·å–å½“å‰è¾“å‡ºæ ¼å¼
    public var outputFormat: String {
        self.tunaSettings.transcriptionFormat
    }

    // è·å–å½“å‰è¾“å‡ºç›®å½•
    public var outputDirectory: URL? {
        self.tunaSettings.transcriptionOutputDirectory
    }

    // MARK: - Private Methods

    private func setupRecordingSession() {
        #if os(iOS)
        // iOSç‰ˆæœ¬ - ä½¿ç”¨AVAudioSession
        // æ£€æŸ¥éº¦å…‹é£æƒé™
        let audioSession = AVAudioSession.sharedInstance()
        audioSession.requestRecordPermission { [weak self] allowed in
            guard let self else { return }

            Task { @MainActor in
                if !allowed {
                    self._progressMessage = "éº¦å…‹é£è®¿é—®æƒé™è¢«æ‹’ç»"
                    self.logger.error("éº¦å…‹é£è®¿é—®æƒé™è¢«æ‹’ç»")
                    return
                }

                self.logger.debug("éº¦å…‹é£è®¿é—®æƒé™å·²æˆäºˆ")
            }
        }
        #else
        // macOSç‰ˆæœ¬ - ä½¿ç”¨AVCaptureDevice
        if #available(macOS 10.14, *) {
            AVCaptureDevice.requestAccess(for: .audio) { [weak self] allowed in
                guard let self else { return }

                Task { @MainActor in
                    if !allowed {
                        self._progressMessage = "éº¦å…‹é£è®¿é—®æƒé™è¢«æ‹’ç»"
                        self.logger.error("éº¦å…‹é£è®¿é—®æƒé™è¢«æ‹’ç»")
                        return
                    }

                    self.logger.debug("éº¦å…‹é£è®¿é—®æƒé™å·²æˆäºˆ")
                }
            }
        } else {
            // æ—§ç‰ˆmacOSé»˜è®¤æœ‰æƒé™
            self.logger.debug("macOS 10.14ä»¥ä¸‹ç‰ˆæœ¬æ— æ³•æ£€æŸ¥éº¦å…‹é£æƒé™ï¼Œé»˜è®¤ç»§ç»­")
        }
        #endif
    }

    private func processRecordings() async {
        guard !self.recordingParts.isEmpty else {
            var newState = self.state
            newState.state = .idle
            self.state = newState
            self.progressMessage = "No recording files"
            self.logger.warning("No recordings to process")
            return
        }

        // è¿‡æ»¤å‡ºæœªå¤„ç†çš„ç‰‡æ®µ
        let unprocessedParts = self.recordingParts.filter { !self.processedSegments.contains($0) }

        if unprocessedParts.isEmpty {
            // æ‰€æœ‰ç‰‡æ®µéƒ½å·²è½¬å½•ï¼Œç›´æ¥å®Œæˆ
            self.logger.debug("All segments already transcribed, skipping duplicate processing")
            await self.finalizeTranscription()

            // æ¸…ç†
            self.recordingParts = []
            self.audioRecorder = nil
            return
        }

        self.logger
            .debug(
                "Processing \(unprocessedParts.count) untranscribed segments, out of \(self.recordingParts.count) total segments"
            )
        self.progressMessage = "Processing new recording parts..."

        // å¦‚æœåªæœ‰ä¸€ä¸ªæœªå¤„ç†çš„ç‰‡æ®µï¼Œç›´æ¥ä½¿ç”¨å®ƒ
        if unprocessedParts.count == 1, let audioURL = unprocessedParts.first {
            await self.transcribeAudio(audioURL)
            return
        }

        // ä½¿ç”¨é€’å½’å‡½æ•°å¤„ç†æœªè½¬å½•çš„ç‰‡æ®µ
        await self.transcribeSegmentsSequentially(
            unprocessedParts,
            currentIndex: 0,
            accumulator: self.transcribedText
        )
    }

    // ä¾æ¬¡å¤„ç†å¤šä¸ªå½•éŸ³ç‰‡æ®µ
    private func transcribeSegmentsSequentially(
        _ segments: [URL],
        currentIndex: Int,
        accumulator: String
    ) async {
        // åŸºç¡€æƒ…å†µï¼šæ‰€æœ‰ç‰‡æ®µéƒ½å·²å¤„ç†
        if currentIndex >= segments.count {
            // å…¨éƒ¨å¤„ç†å®Œæˆï¼Œæ›´æ–°çŠ¶æ€
            self.transcribedText = accumulator
            await self.finalizeTranscription()

            // æ¸…ç†
            self.recordingParts = []
            self.audioRecorder = nil
            return
        }

        // è·å–å½“å‰ç‰‡æ®µ
        let currentSegment = segments[currentIndex]

        // å¦‚æœè¯¥ç‰‡æ®µå·²ç»è¢«å¤„ç†è¿‡ï¼Œç›´æ¥è·³åˆ°ä¸‹ä¸€ä¸ª
        if self.processedSegments.contains(currentSegment) {
            self.logger.debug("ç‰‡æ®µå·²å¤„ç†è¿‡ï¼Œè·³è¿‡: \(currentSegment.path)")
            await self.transcribeSegmentsSequentially(
                segments,
                currentIndex: currentIndex + 1,
                accumulator: accumulator
            )
            return
        }

        self.progressMessage = "Transcribing segment \(currentIndex + 1)/\(segments.count)..."
        self.logger
            .debug(
                "Transcribing segment \(currentIndex + 1)/\(segments.count): \(currentSegment.path)"
            )

        // è½¬å½•å½“å‰ç‰‡æ®µ
        await self.callWhisperAPI(audioURL: currentSegment) { [weak self] result in
            guard let self else { return }

            Task { @MainActor in
                switch result {
                    case let .success(segmentText):
                        // å°†å½“å‰ç‰‡æ®µçš„è½¬å½•ç»“æœæ·»åŠ åˆ°ç´¯åŠ å™¨
                        var newAccumulator = accumulator
                        if !newAccumulator.isEmpty, !segmentText.isEmpty {
                            newAccumulator += "\n"
                        }
                        newAccumulator += segmentText

                        // æ ‡è®°è¯¥ç‰‡æ®µå·²å¤„ç†
                        self.processedSegments.insert(currentSegment)

                        // é€’å½’å¤„ç†ä¸‹ä¸€ä¸ªç‰‡æ®µ
                        Task {
                            await self.transcribeSegmentsSequentially(
                                segments,
                                currentIndex: currentIndex + 1,
                                accumulator: newAccumulator
                            )
                        }

                    case let .failure(error):
                        self.logger
                            .error(
                                "Failed to transcribe segment \(currentIndex + 1): \(error.localizedDescription)"
                            )

                        // å³ä½¿å½“å‰ç‰‡æ®µå¤±è´¥ï¼Œä¹Ÿç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªç‰‡æ®µ
                        Task {
                            await self.transcribeSegmentsSequentially(
                                segments,
                                currentIndex: currentIndex + 1,
                                accumulator: accumulator
                            )
                        }
                }
            }
        }
    }

    @MainActor
    private func transcribeAudio(_ audioURL: URL) async {
        // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
        guard !self.apiKey.isEmpty else {
            self._state.state = .error(DictationError.noAPIKey)
            self._progressMessage = "Please set API key in settings"
            self.logger.error("API key not set")
            self.notifierType.post(NSNotification.Name.dictationAPIKeyMissing, object: nil)
            return
        }

        self._progressMessage = "Transcribing audio..."
        self.logger.debug("Transcribing audio from \(audioURL.path)")

        // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å¯è¯»
        guard FileManager.default.fileExists(atPath: audioURL.path) else {
            self._state.state = .error(DictationError.audioFileReadError)
            self._progressMessage = "Cannot read audio file"
            self.logger.error("Failed to read audio file")
            return
        }

        // è°ƒç”¨Whisper APIè¿›è¡Œè½¬å½•
        self.callWhisperAPI(audioURL: audioURL) { [weak self] result in
            guard let self else { return }

            Task { @MainActor in
                switch result {
                    case let .success(transcribedText):
                        // è®¾ç½®è½¬å½•æ–‡æœ¬ï¼Œä½¿ç”¨APIè¿”å›çš„å®é™…å†…å®¹
                        self._transcribedText = transcribedText

                        // æ ‡è®°è¯¥æ–‡ä»¶å·²å¤„ç†
                        self.processedSegments.insert(audioURL)

                        // ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªç‰‡æ®µ
                        await self.processRecordings()

                    case let .failure(error):
                        self
                            ._progressMessage =
                            "Transcription failed: \(error.localizedDescription)"
                        self.logger.error("Transcription failed: \(error.localizedDescription)")
                        self._state.state = .error(DictationError.transcriptionFailed(error))
                        self.notifierType.post(NSNotification.Name.dictationError, object: error)
                }
            }
        }
    }

    // è½¬å½•å½“å‰å½•éŸ³ç‰‡æ®µï¼Œä½†ä¿æŒå½•éŸ³çŠ¶æ€
    private func transcribeCurrentSegment(_ audioURL: URL) {
        // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
        guard !self.apiKey.isEmpty else {
            self._progressMessage = "Please set API key in settings"
            self.logger.error("API key not set")
            self._state.state = .error(DictationError.noAPIKey)

            // å‘é€é€šçŸ¥ï¼Œè¡¨ç¤ºç¼ºå°‘APIå¯†é’¥
            Task { @MainActor in
                self.notifierType.post(NSNotification.Name.dictationAPIKeyMissing, object: nil)
            }
            return
        }

        self._progressMessage = "Transcribing current segment..."
        self.logger.debug("Transcribing current segment from \(audioURL.path)")

        // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å¯è¯»
        guard FileManager.default.fileExists(atPath: audioURL.path) else {
            self._progressMessage = "Cannot read audio file"
            self.logger.error("Failed to read audio file")
            self._state.state = .error(DictationError.audioFileReadError)
            return
        }

        // è°ƒç”¨Whisper APIè½¬å½•å½“å‰ç‰‡æ®µ
        self.callWhisperAPI(audioURL: audioURL) { [weak self] result in
            guard let self else { return }

            Task { @MainActor in
                switch result {
                    case let .success(segmentText):
                        // è¿½åŠ è½¬å½•æ–‡æœ¬ï¼Œè€Œä¸æ˜¯æ›¿æ¢
                        if self.transcribedText.isEmpty {
                            self.transcribedText = segmentText
                        } else {
                            // å…ˆå¤‡ä»½å½“å‰å€¼ï¼Œç„¶åè®¾ç½®æ–°å€¼ä»¥ç¡®ä¿UIæ›´æ–°
                            let newText = self.transcribedText + "\n" + segmentText
                            self.transcribedText = ""
                            self.transcribedText = newText
                        }

                        // æ ‡è®°æ­¤ç‰‡æ®µå·²å¤„ç†
                        self.processedSegments.insert(audioURL)

                        // æ›´æ–°çŠ¶æ€æ¶ˆæ¯
                        self._progressMessage = "Paused - partial content transcribed"
                        self.logger.debug("Current segment transcribed successfully")

                        // æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è‡ªåŠ¨å¤åˆ¶åŠŸèƒ½ï¼Œå¦‚æœæ˜¯åˆ™å¤åˆ¶å½“å‰è½¬å½•æ–‡æœ¬åˆ°å‰ªè´´æ¿
                        if self.tunaSettings.autoCopyTranscriptionToClipboard {
                            NSPasteboard.general.clearContents()
                            NSPasteboard.general.setString(self.transcribedText, forType: .string)
                            self.logger.debug("Auto-copied transcription to clipboard")
                            self
                                ._progressMessage =
                                "Transcription completed and copied to clipboard"
                        }

                    case let .failure(error):
                        self
                            ._progressMessage =
                            "Partial transcription failed: \(error.localizedDescription)"
                        self.logger
                            .error("Segment transcription failed: \(error.localizedDescription)")
                        self._state.state = .error(DictationError.transcriptionFailed(error))
                        self.notifierType.post(NSNotification.Name.dictationError, object: error)
                }
            }
        }
    }

    // è°ƒç”¨OpenAI Whisper API
    private func callWhisperAPI(
        audioURL: URL,
        completion: @escaping (Result<String, Error>) -> Void
    ) {
        // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
        guard !self.apiKey.isEmpty else {
            completion(.failure(DictationError.noAPIKey))
            return
        }

        // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¹¶è·å–æ–‡ä»¶å¤§å°
        guard let audioData = try? Data(contentsOf: audioURL) else {
            completion(.failure(DictationError.audioFileReadError))
            return
        }

        // è®°å½•éŸ³é¢‘æ–‡ä»¶å¤§å°ï¼Œç”¨äºè°ƒè¯•
        let fileSizeBytes = audioData.count
        let fileSizeKB = Double(fileSizeBytes) / 1024.0
        self.logger.debug("Audio file size: \(fileSizeKB) KB")

        // æ£€æŸ¥æ–‡ä»¶å¤§å° - Whisper APIå¯¹æ–‡ä»¶å¤§å°æœ‰é™åˆ¶
        if fileSizeBytes < 1024 { // å°‘äº1KBï¼Œå¯èƒ½å¤ªå°
            self.logger.warning("Audio file may be too small (\(fileSizeKB) KB)")
            // ä»ç„¶å°è¯•å‘é€ï¼Œä½†è®°å½•è­¦å‘Š
        }

        if fileSizeBytes > 25 * 1024 * 1024 { // å¤§äº25MB
            completion(.failure(NSError(
                domain: "com.tuna.error",
                code: 413,
                userInfo: [
                    NSLocalizedDescriptionKey: "Audio file too large: \(fileSizeKB) KB, exceeds API limit",
                ]
            )))
            return
        }

        // åˆ›å»ºboundaryç”¨äºmultipartè¯·æ±‚
        let boundary = "Boundary-\(UUID().uuidString)"

        // è®¾ç½®API URL
        guard let url = URL(string: "https://api.openai.com/v1/audio/transcriptions") else {
            completion(.failure(NSError(
                domain: "com.tuna.error",
                code: 500,
                userInfo: [NSLocalizedDescriptionKey: "Invalid API URL"]
            )))
            return
        }

        // åˆ›å»ºè¯·æ±‚
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("Bearer \(self.apiKey)", forHTTPHeaderField: "Authorization")
        request.setValue(
            "multipart/form-data; boundary=\(boundary)",
            forHTTPHeaderField: "Content-Type"
        )

        // åˆ›å»ºmultipartè¯·æ±‚ä½“
        var body = Data()

        // æ·»åŠ æ–‡ä»¶
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body
            .append(
                "Content-Disposition: form-data; name=\"file\"; filename=\"audio.wav\"\r\n"
                    .data(using: .utf8)!
            )
        body.append("Content-Type: audio/wav\r\n\r\n".data(using: .utf8)!)
        body.append(audioData)
        body.append("\r\n".data(using: .utf8)!)

        // æ·»åŠ æ¨¡å‹å‚æ•°
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"model\"\r\n\r\n".data(using: .utf8)!)
        body.append("whisper-1\r\n".data(using: .utf8)!)

        // æ·»åŠ è¯­è¨€å‚æ•°ï¼ˆå¦‚æœè®¾ç½®äº†ï¼‰
        if !self.tunaSettings.transcriptionLanguage.isEmpty {
            body.append("--\(boundary)\r\n".data(using: .utf8)!)
            body
                .append(
                    "Content-Disposition: form-data; name=\"language\"\r\n\r\n"
                        .data(using: .utf8)!
                )
            body.append("\(self.tunaSettings.transcriptionLanguage)\r\n".data(using: .utf8)!)
        }

        // æ·»åŠ æ ¼å¼å‚æ•°
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body
            .append(
                "Content-Disposition: form-data; name=\"response_format\"\r\n\r\n"
                    .data(using: .utf8)!
            )
        body.append("text\r\n".data(using: .utf8)!)

        // ç»“æŸboundary
        body.append("--\(boundary)--\r\n".data(using: .utf8)!)

        request.httpBody = body

        // åˆ›å»ºä»»åŠ¡
        let task = URLSession.shared.dataTask(with: request) { [weak self] data, response, error in
            guard let self else { return }

            if let error {
                completion(.failure(error))
                return
            }

            guard let httpResponse = response as? HTTPURLResponse else {
                completion(.failure(NSError(
                    domain: "com.tuna.error",
                    code: 500,
                    userInfo: [NSLocalizedDescriptionKey: "Invalid response type"]
                )))
                return
            }

            guard (200 ... 299).contains(httpResponse.statusCode) else {
                completion(.failure(NSError(
                    domain: "com.tuna.error",
                    code: httpResponse.statusCode,
                    userInfo: [
                        NSLocalizedDescriptionKey: "API request failed with status code: \(httpResponse.statusCode)",
                    ]
                )))
                return
            }

            guard let data else {
                completion(.failure(NSError(
                    domain: "com.tuna.error",
                    code: 500,
                    userInfo: [NSLocalizedDescriptionKey: "No data received"]
                )))
                return
            }

            // è§£æå“åº”
            if let transcribedText = String(data: data, encoding: .utf8) {
                completion(.success(
                    transcribedText
                        .trimmingCharacters(in: .whitespacesAndNewlines)
                ))
            } else {
                completion(.failure(NSError(
                    domain: "com.tuna.error",
                    code: 500,
                    userInfo: [NSLocalizedDescriptionKey: "Failed to decode response"]
                )))
            }
        }

        task.resume()
    }

    // è®¡ç®—æ–‡æœ¬ä¸­çš„å•è¯æ•°
    private func countWords(in text: String) -> Int {
        text.components(separatedBy: .whitespacesAndNewlines)
            .filter { !$0.isEmpty }
            .count
    }

    // æ›¿æ¢åŸæœ‰çš„finalizeTranscriptionæ–¹æ³•
    @MainActor
    func finalizeTranscription() async {
        self._state.state = .idle

        // è®¡ç®—å•è¯æ•°
        let wordCount = self.countWords(in: self._transcribedText)

        // å‘é€å®Œæˆé€šçŸ¥ï¼ŒåŒ…å«è¯æ•°ä¿¡æ¯
        self.notifierType.post(NSNotification.Name.dictationFinished, object: nil)

        if self.transcribedText.isEmpty {
            self._progressMessage = "Transcription failed, no text result"
        } else {
            // æ·»åŠ è¯æ•°ä¿¡æ¯åˆ°è¿›åº¦æ¶ˆæ¯
            self._progressMessage =
                "Transcription completed (\(wordCount) words) - click Save to save"

            // æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è‡ªåŠ¨å¤åˆ¶åŠŸèƒ½ï¼Œå¦‚æœæ˜¯åˆ™å¤åˆ¶åˆ°å‰ªè´´æ¿
            if self.tunaSettings.autoCopyTranscriptionToClipboard {
                NSPasteboard.general.clearContents()
                NSPasteboard.general.setString(self.transcribedText, forType: .string)
                self.logger.debug("Auto-copied transcription to clipboard")
                self._progressMessage = "Transcription completed and copied to clipboard"
            }
        }

        self._state.breathingAnimation = false
        self.logger.debug("Completed transcription. Word count: \(wordCount)")
    }

    // æ·»åŠ ä¸€ä¸ªå®ç”¨å·¥å…·æ–¹æ³•ï¼Œç”¨äºå‘é€é€šçŸ¥
    private func sendDebugNotification(message: String) {
        print("ğŸ“£ [DEBUG] DictationManager: \(message)")
        Task { @MainActor in
            self.notifierType.post(NSNotification.Name.dictationDebugMessage, object: nil)
        }
    }

    // æ›´æ–°APIå¯†é’¥
    public func updateAPIKey(_ key: String) async {
        do {
            try self.secureStore.set(
                value: key.data(using: .utf8)!,
                forKey: SecureStore.defaultAccount,
                account: SecureStore.defaultAccount
            )
            self.notifierType.post(NSNotification.Name.dictationAPIKeyUpdated, object: nil)
        } catch {
            self.logger.error("Failed to save API key to Keychain: \(error.localizedDescription)")
            self.notifierType.post(NSNotification.Name.dictationAPIKeyMissing, object: nil)
        }
    }

    public func updateState(_ newState: DictationState) {
        self._state = newState
    }

    public func updateProgressMessage(_ message: String) {
        self._progressMessage = message
    }

    public func updateTranscribedText(_ text: String) {
        self._transcribedText = text
    }

    private func handlePlayPauseAction() async {
        let state = self.state.state
        switch state {
            case .idle:
                await self.startRecording()
            case .recording:
                await self.pauseRecording()
            case .paused:
                await self.continueRecording()
            case .processing:
                self.logger.notice("Cannot toggle - processing")
            case .error:
                print("\u{001B}[31m[ERROR]\u{001B}[0m å½•éŸ³å¤„äºé”™è¯¯çŠ¶æ€ï¼Œå°è¯•é‡ç½®")
                var newState = self.state
                newState.state = .idle
                self.state = newState
        }
    }

    // æ’­æ”¾/æš‚åœæŒ‰é’®å›¾æ ‡
    public nonisolated var playPauseIconName: String {
        get async {
            await withCheckedContinuation { continuation in
                Task { @MainActor in
                    let icon = switch self._state.state {
                        case .idle, .paused:
                            "play.fill"
                        case .recording:
                            "pause.fill"
                        case .processing:
                            "hourglass"
                        case .error:
                            "exclamationmark.triangle.fill"
                    }
                    continuation.resume(returning: icon)
                }
            }
        }
    }

    // çŠ¶æ€æ–‡æœ¬
    public nonisolated var statusText: String {
        get async {
            await withCheckedContinuation { continuation in
                Task { @MainActor in
                    let text: String = if self._state.state == .recording {
                        "Listening..."
                    } else if !self._progressMessage.isEmpty {
                        self._progressMessage
                    } else if self._transcribedText.isEmpty,
                              self._state.state == .idle
                    {
                        "No recording files"
                    } else {
                        switch self._state.state {
                            case .idle:
                                "Ready to record"
                            case .recording:
                                "Recording..."
                            case .paused:
                                "Paused"
                            case .processing:
                                "Processing..."
                            case .error:
                                "Error"
                        }
                    }
                    continuation.resume(returning: text)
                }
            }
        }
    }

    public func startDictation() async {
        var newState = self.state
        newState.state = .recording
        self.state = newState
        // TODO: Implement actual dictation
    }

    public func stopDictation() async {
        var newState = self.state
        newState.state = .idle
        self.state = newState
        // TODO: Implement actual dictation stop
    }

    public func toggleDictation() async {
        if self.isRecording {
            await self.stopDictation()
        } else {
            await self.startDictation()
        }
    }

    public func showDictationWindow() async {
        // TODO: Implement window showing logic
        // This will be handled by the UI layer
    }
}

extension DictationManager: AVAudioRecorderDelegate {
    public nonisolated func audioRecorderDidFinishRecording(
        _ recorder: AVAudioRecorder,
        successfully flag: Bool
    ) {
        Task { @MainActor in
            if !flag {
                self.logger.error("Recording failed")
                self._state.state = .error(DictationError.recordingFailed)
                self.onStartFailure?()
            }
        }
    }

    public nonisolated func audioRecorderEncodeErrorDidOccur(
        _ recorder: AVAudioRecorder,
        error: Error?
    ) {
        Task { @MainActor in
            if let error {
                self.logger.error("Recording encode error: \(error.localizedDescription)")
                self._state.state = .error(DictationError.recordingFailed)
                self.onStartFailure?()
            }
        }
    }
}
